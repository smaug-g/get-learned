{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "#from imgaug import augmenters as iaa      --> used for Gaussian Blur that is not working right now.\n",
    "import pandas as pd\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras import regularizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT: Change the values of num_train and num_validate below to actual values you used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_directory = '/Users/louissmidt/ELEC 301 Final Project/train_posters'\n",
    "val_directory = '/Users/louissmidt/ELEC 301 Final Project/validation_posters'\n",
    "num_train = 2894\n",
    "num_validate = 200 \n",
    "nv = num_validate // batch_size\n",
    "nt = num_train // batch_size\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guassian Blur is using ImgAug library, it does not work right now. Skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def gaussian_blur(img):\n",
    "#    \"\"\"\n",
    "#    Gaussian Blur of varying intensity applied to 30% of augmented images .\n",
    "#    Called after resize and augmentation. Input Rank = 3, Output Rank = 3, \n",
    "#   imgaug requires Rank=4\n",
    "#    \"\"\"\n",
    "#    aug = iaa.Sometimes(0.3, iaa.GaussianBlur(sigma=(0.1, 0.3)))\n",
    "#    return aug.augment_images([img])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_144 (Conv2D)          (None, 265, 179, 32)      1568      \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 265, 179, 32)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 132, 89, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 129, 86, 32)       16416     \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 129, 86, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 32, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 30, 19, 16)        4624      \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 30, 19, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 15, 9, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 2160)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 64)                138304    \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 161,172\n",
      "Trainable params: 161,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#IMG dimensions: 182 * 268 * 3\n",
    "model = Sequential()  \n",
    "model.add(Conv2D(32, (4,4), input_shape=(268, 182, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "          \n",
    "model.add(Conv2D(32, (4, 4), activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "                    \n",
    "model.add(Conv2D(16, (3, 3), activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data generators that feed mini batches into the model for training and validation. The train_datagen uses Keras data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2894 images belonging to 4 classes.\n",
      "Found 200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    #preprocessing_function=gaussian_blur(),\n",
    "    rotation_range=25,\n",
    "    brightness_range=[0, 0.2],\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    #featurewise_center=True,\n",
    "    #zca_whitening=True,\n",
    "    #vertical_flip=True,\n",
    "    #orizontal_flip=False,\n",
    "    fill_mode=\"nearest\",\n",
    "    rescale=1./255)\n",
    "    #validation_split=0.2)\n",
    "    \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_directory,\n",
    "        target_size=(268, 182),  \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "        #subset=\"training\") \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        val_directory,\n",
    "        target_size=(268, 182),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model to the Generators --> it'll print accuracy against the validation set at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "90/90 [==============================] - 141s 2s/step - loss: nan - acc: 0.2035 - val_loss: nan - val_acc: 0.3177\n",
      "Epoch 2/5\n",
      "90/90 [==============================] - 139s 2s/step - loss: nan - acc: 0.2052 - val_loss: nan - val_acc: 0.3036\n",
      "Epoch 3/5\n",
      "90/90 [==============================] - 143s 2s/step - loss: nan - acc: 0.2005 - val_loss: nan - val_acc: 0.3214\n",
      "Epoch 4/5\n",
      "90/90 [==============================] - 141s 2s/step - loss: nan - acc: 0.2047 - val_loss: nan - val_acc: 0.3095\n",
      "Epoch 5/5\n",
      "90/90 [==============================] - 141s 2s/step - loss: nan - acc: 0.1999 - val_loss: nan - val_acc: 0.3452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3fa3eef0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, verbose=1,\n",
    "                   steps_per_epoch= nt,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps= nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model1.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "### Next Cells fit the data from a numpy matrix manually if the generator based method does not work. Bypasses data augmentation. \n",
    "#### Only run if you want the training data as a matrix in memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import images and labels for training, separate into train and validate (first 200)\n",
    "\n",
    "meta = pd.read_csv(\"train_data.csv\", index_col=0)\n",
    "trainLab = meta[\"Genre\"][:2894]\n",
    "valLab = meta[\"Genre\"][2895:3094]\n",
    "\n",
    "train_data = np.zeros((2894, 268, 182, 3)) # rgb channels last\n",
    "val_data = np.zeros((200, 268, 182, 3))\n",
    "\n",
    "#populate train_data\n",
    "tInd = 0\n",
    "for filename in os.listdir(train_directory):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        imgDir = train_dir + \"/\" + str(filename)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    img = load_img(imgDir)\n",
    "    imgX = img_to_array(img)\n",
    "    train_data[tInd] = imgX\n",
    "    tInd += 1\n",
    "\n",
    "#populate train_data\n",
    "vInd = 0\n",
    "for filename in os.listdir(val_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        imgDir = val_dir + \"/\" + str(filename)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    img = load_img(imgDir)\n",
    "    imgX = img_to_array(img)\n",
    "    val_data[vInd] = imgX\n",
    "    vInd += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images for testing\n",
    "\n",
    "dir2 = '/Users/louissmidt/ELEC 301 Final Project/test_posters'\n",
    "\n",
    "test_data = np.zeros((344, 268, 182, 3)) # rgb channels last\n",
    "\n",
    "ind2 = 0\n",
    "for filename in os.listdir(dir2):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        imgDir = dir2 + \"/\" + str(filename)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    img = load_img(imgDir)\n",
    "    imgX = img_to_array(img)\n",
    "    test_data[ind2] = imgX\n",
    "    ind2 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual fit, not from Generator (Not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_y_1 = LabelEncoder()\n",
    "y = labelencoder_y_1.fit_transform(trainLab)\n",
    "\n",
    "model.fit(x=train_data, y=trainLab, batch_size=batch_size, epochs=10, verbose=2, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
